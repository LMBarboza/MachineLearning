{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cqqgb6uHuvXE"
   },
   "source": [
    "# Aprendizagem de Máquina I\n",
    "\n",
    "## Hugo Tremonte de Carvalho\n",
    "\n",
    "#### hugo@dme.ufrj.br"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Oncov0yIuvXI"
   },
   "source": [
    "NOMES:\n",
    "* Leon Martins Uchoa Barboza"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y2O5K2D3uvXJ"
   },
   "source": [
    "Este _notebook_ é correspondente ao nosso segundo projeto, passado no dia 19/09/2024 e para entrega no dia 17/10/2024. Ele consiste em resolver um problema prático e responder a duas questões teóricas. A entrega da atividade deve ser feita através do Google Classroom, fazendo um _upload_ deste _notebook_, devidamente atualizado com as suas resoluções e implementações. Recomendo fortemente que façam o trabalho no Google Colab, pois assim temos certa garantia de estarmos rodando tudo no mesmo ambiente e que eu conseguir executar o código de vocês sem dificuldades.\n",
    "\n",
    "O projeto poderá ser feito **até** em dupla: quem quer fazer sozinho/a faz, mas quem quiser fazer em dupla também tem esse direito."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_SiQI53-uvXK"
   },
   "source": [
    "# Parte teórica"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vdrg80bNuvXL"
   },
   "source": [
    "## Exercício 01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cWJ98ZrjuvXL"
   },
   "source": [
    "O objetivo dessa questão é estudar um pouco da *Maldição da Dimensionalidade* (https://en.wikipedia.org/wiki/Curse_of_dimensionality). De modo mais concreto, queremos estudar a seguinte afirmação, de ordem um pouco esotética:\n",
    "\n",
    "*À medida que $p$ cresce, o volume do hipercubo $\\mathbb{H}^p = [0, 1]^p$ fica cada vez mais concentrado em sua \"casca\" do que em seu interior.*\n",
    "\n",
    "Para isso, faça o que se pede abaixo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vFEHXi_xuvXM"
   },
   "source": [
    "a) Apesar de esotérica, fazer a prova de tal afirmação é bastante simples! Seja $\\mathbb{H}^p_{\\varepsilon}$ o hipercubo contido em $\\mathbb{H}^p$ obtido removendo-se uma \"gordurinha\" de tamanho $\\varepsilon$ de sua beirada, ou seja, $\\mathbb{H}^p_{\\varepsilon} = [\\varepsilon/2, 1 - \\varepsilon/2]^p$. Mostre que o volume de $\\mathbb{H}^p_{\\varepsilon}$ converge para zero, para todo $\\varepsilon > 0$, quando $p \\to \\infty$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QWX0NgP0uvXN"
   },
   "source": [
    "b) Particularmente, para mim essa demonstação não me ajuda a ter nenhuma intuição sobre o resultado, e ele continua sendo esotérico! Porém, um dia tive uma revelação divina que cá partilho com vocês. Fixe algum valor de $0 < \\varepsilon < 1$ à sua escolha e simule $n$ vetores de tamanho $p$ de observações de uma variável aleatória uniforme no intervalo $[0, 1]$. Qual é a proporção desses vetores que não têm nenhuma observação fora do hipercubo $\\mathbb{H}^p_{\\varepsilon}$? Faça uma explicação, baseada em tal experimento, para justificar empiricamente o resultado que você provou no item a)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4rpfA1GduvXN"
   },
   "source": [
    "## Exercício 02"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DpbslqSGuvXO"
   },
   "source": [
    "O objetivo dessa questão é provar o que foi exibido sobre a maldição da dimensionalidade ao final da aula 4. Considere um conjunto de dados artificial de $n$ observações, onde cada observação consiste de um vetor de $p$ atributos, sendo cada entrada uniformemente distribuída em $(0, 1)$. Chamaremos tal conjunto de dados de $\\mathbb{X}$. Sejam $\\mathbf{X}^{(i)}$ e $\\mathbf{X}^{(j)}$ duas linhas distintas da matriz $\\mathbb{X}$, ou seja, dois vetores independentes de observações, ambos de tamanho $p$, consistindo de entradas independentes e identicamente distribuídas com distribuição uniforme no intervalo $(0, 1)$, estude o que acontece com a quantidade abaixo, chamada de *coeficiente de variação* à medida que $p \\to \\infty$:\n",
    "\n",
    "\\begin{equation*}\n",
    "\\frac{\\sqrt{\\mathbb{V}\\left(\\left\\|\\mathbf{X}^{(i)} - \\mathbf{X}^{(j)}\\right\\|^2\\right)}}{\\mathbb{E}\\left[\\left\\|\\mathbf{X}^{(i)} - \\mathbf{X}^{(j)}\\right\\|^2\\right]}.\n",
    "\\end{equation*}\n",
    "\n",
    "Relacione esse resultado com o comportamento apresentado nos *slides* da aula 4."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cY6LfQp2uvXO"
   },
   "source": [
    "# Parte prática"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uF5HdKnwuvXO"
   },
   "source": [
    "O objetivo da parte prática é analisar uma base de dados contendo informações sobre corridas de Uber, e tentar prever o valor da corrida com base em atributos de interesse. A base de dados encontra-se disponível [aqui](https://www.kaggle.com/datasets/yasserh/uber-fares-dataset).\n",
    "\n",
    "O arquivo `.csv` tem poucas colunas: `fare_amount` é a coluna que desejamos prever, e temos também as colunas abaixo para usar como preditoras:\n",
    "* `key` - _a unique identifier for each trip_\n",
    "* `pickup_datetime` - _date and time when the meter was engaged_\n",
    "* `passenger_count` - _the number of passengers in the vehicle (driver entered value)_\n",
    "* `pickup_longitude` - _the longitude where the meter was engaged_\n",
    "* `pickup_latitude` - _the latitude where the meter was engaged_\n",
    "* `dropoff_longitude` - _the longitude where the meter was disengaged_\n",
    "* `dropoff_latitude` - _the latitude where the meter was disengaged_\n",
    "\n",
    "Note que a coluna `key` não será um preditor, já que contém somente uma variável de identificação da corrida. Porém, para que as outras colunas sejam propriamente utilizadas como preditoras, talvez seja necessário algum pré-processamento:\n",
    "* Precisaremos converter as informações de latitude e longitude em distância ou nossos algoritmos serão capazes de fazê-lo \"automaticamente\"? Mesmo caso o façam, ter a distância logo de cara auxilia no processo de previsão?\n",
    "* A coluna `pickup_datetime` tem muita informação útil, e pode ser convertida em muitas outras informações para te auxiliar na predição, por exemplo: dia da semana da corrida, se é feriado ou não, etc... porém, essas informações não são imediatas e vão requerer um certo \"trabalho sujo\" da sua parte, bem como um tico de ferramentas de processamento de texto :-)\n",
    "* Note que, ao converter `pickup_datetime` para, digamos, dia da semana, será necessário converter essa informação em algo numérico. Aplicar `One Hot Encoding` é uma boa opção? Estude isso com carinho.\n",
    "\n",
    "Alguns pontos que o seu trabalho deve conter:\n",
    "* Análise exploratória bem aprofundada e interpretada: os nossos dados são muito interpretáveis! Além de fazer o que já esperamos (estudar correlações, visualizar histogramas, etc.), sua análise exploratória deve ser esclarecedora sobre distância entre ponto de partida e ponto de chegada, distribuição das corridas ao longo dos dias da semana, distribuição das corridas ao longo dos meses, estudar como (potencialmente) os atributos se relacionam com a resposta (sem e com pré-processamento), analisar (possível) influência do número de passageiros no preço da corrida, etc... Portanto, não basta fazer meia dúzia de gráficos para \"cumprir tabela\"! A análise exploratória deve informar muito sobre a base de dados e guiar os próximos passos!\n",
    "* Criação de novos atributos a partir das colunas já presentes na base\n",
    "* Treinamento e validação de todos os modelos de regressão que vimos até o momento, juntamente com uma interpretação de seus resultados\n",
    "* Em particular, os coeficientes das regressões paramétricas devem ser interpretados, bem como a `feature_importance_` dos modelos baseados em árvores.\n",
    "* Decisão de um \"melhor\" modelo para realizar previsões, com justificativa\n",
    "\n",
    "Tome cuidado que a base é grande: poucos atributos porém muitas linhas! É bem provável que você precise tomar cuidado ao usar métodos pesados como `GridSearchCV`, ou até mesmo nos métodos `.fit()` dos nossos estimadores. Usar as coisas ingenuamente pode ser computacionalmente inviável. Seja sagaz em suas escolhas!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset URL: https://www.kaggle.com/datasets/yasserh/uber-fares-dataset\n",
      "License(s): CC0-1.0\n",
      "Downloading uber-fares-dataset.zip to data\n",
      " 85%|████████████████████████████████▍     | 6.00M/7.04M [00:00<00:00, 11.2MB/s]\n",
      "100%|██████████████████████████████████████| 7.04M/7.04M [00:00<00:00, 10.9MB/s]\n"
     ]
    }
   ],
   "source": [
    "!kaggle datasets download yasserh/uber-fares-dataset -p data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  data/uber-fares-dataset.zip\n",
      "  inflating: data/uber.csv           \n"
     ]
    }
   ],
   "source": [
    "!unzip data/uber-fares-dataset.zip -d data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'geopandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[78], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mgeopandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mgpd\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mshapely\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgeometry\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Point\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'geopandas'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "from shapely.geometry import Point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "df: pd.DataFrame = pd.read_csv(\"data/uber.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values(by=\"key\", inplace=True)\n",
    "df.drop(columns=[\"Unnamed: 0\", \"key\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(inplace=True)\n",
    "df.dropna(subset=[\"fare_amount\", \"pickup_datetime\", \n",
    "                  \"pickup_longitude\", \"pickup_latitude\", \n",
    "                  \"dropoff_longitude\", \"dropoff_latitude\", \n",
    "                  \"passenger_count\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(df[(df[\"passenger_count\"] < 0) | (df[\"passenger_count\"] > 6)].index, inplace=True)\n",
    "df.drop(df[df[\"fare_amount\"] <= 0].index, inplace=True)\n",
    "df.query(\n",
    "    \"-90 <= pickup_latitude <= 90 and -180 <= pickup_longitude <= 180 and \"\n",
    "    \"-90 <= dropoff_latitude <= 90 and -180 <= dropoff_longitude <= 180\",\n",
    "    inplace=True\n",
    ")\n",
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"pickup_datetime\"] = pd.to_datetime(df[\"pickup_datetime\"], utc=True)\n",
    "df[\"weekday\"] = df[\"pickup_datetime\"].dt.day_name() \n",
    "df[\"hour\"] = df[\"pickup_datetime\"].dt.hour\n",
    "df[\"day\"] = df[\"pickup_datetime\"].dt.day\n",
    "df[\"month\"] = df[\"pickup_datetime\"].dt.month\n",
    "df[\"year\"] = df[\"pickup_datetime\"].dt.year\n",
    "#verificar que dados são de nova york"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create GeoDataFrame\n",
    "geometry = [Point(xy) for xy in zip(df[\"pickup_longitude\"], df[\"pickup_latitude\"])]\n",
    "gdf = gpd.GeoDataFrame(df, geometry=geometry)\n",
    "\n",
    "# Load a map of the world (or a specific region) from geopandas\n",
    "world = gpd.read_file(gpd.datasets.get_path('naturalearth_lowres'))\n",
    "\n",
    "# Plot the map and points\n",
    "ax = world.plot(figsize=(10, 6))\n",
    "\n",
    "# Plot the points\n",
    "gdf.plot(ax=ax, color='red', marker='o', markersize=5)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "EARTH_R = 6371.0088\n",
    "def _haversine_kernel(lat1: float, lng1: float, lat2: float, lng2: float) -> float:\n",
    "    lat1 = np.radians(lat1)\n",
    "    lng1 = np.radians(lng1)\n",
    "    lat2 = np.radians(lat2)\n",
    "    lng2 = np.radians(lng2)\n",
    "    \n",
    "    lat = lat2 - lat1\n",
    "    lng = lng2 - lng1\n",
    "    d = (np.sin(lat * 0.5) ** 2 + \n",
    "         np.cos(lat1) * np.cos(lat2) * np.sin(lng * 0.5) ** 2)\n",
    "    \n",
    "    return 2 * EARTH_R * np.arcsin(np.sqrt(d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "longitude = df[\"pickup_longitude\"].iloc[0]\n",
    "latitude = df[\"pickup_latitude\"].iloc[0]\n",
    "df[\"distance\"] = df.apply(lambda row: _haversine_kernel(reference_longitude, reference_latitude, \n",
    "                                                   row[\"pickup_longitude\"], row[\"pickup_latitude\"]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(df[df[\"distance\"] < 0.05].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fare_amount                      float64\n",
       "pickup_datetime      datetime64[ns, UTC]\n",
       "pickup_longitude                 float64\n",
       "pickup_latitude                  float64\n",
       "dropoff_longitude                float64\n",
       "dropoff_latitude                 float64\n",
       "passenger_count                    int64\n",
       "weekday                           object\n",
       "day                                int32\n",
       "month                              int32\n",
       "year                               int32\n",
       "distance                         float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "MachineLearning venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
