{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cqqgb6uHuvXE"
   },
   "source": [
    "# Aprendizagem de Máquina I\n",
    "\n",
    "## Hugo Tremonte de Carvalho\n",
    "\n",
    "#### hugo@dme.ufrj.br"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Oncov0yIuvXI"
   },
   "source": [
    "NOMES:\n",
    "* Leon Martins Uchoa Barboza"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y2O5K2D3uvXJ"
   },
   "source": [
    "Este _notebook_ é correspondente ao nosso segundo projeto, passado no dia 19/09/2024 e para entrega no dia 17/10/2024. Ele consiste em resolver um problema prático e responder a duas questões teóricas. A entrega da atividade deve ser feita através do Google Classroom, fazendo um _upload_ deste _notebook_, devidamente atualizado com as suas resoluções e implementações. Recomendo fortemente que façam o trabalho no Google Colab, pois assim temos certa garantia de estarmos rodando tudo no mesmo ambiente e que eu conseguir executar o código de vocês sem dificuldades.\n",
    "\n",
    "O projeto poderá ser feito **até** em dupla: quem quer fazer sozinho/a faz, mas quem quiser fazer em dupla também tem esse direito."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_SiQI53-uvXK"
   },
   "source": [
    "# Parte teórica"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vdrg80bNuvXL"
   },
   "source": [
    "## Exercício 01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cWJ98ZrjuvXL"
   },
   "source": [
    "O objetivo dessa questão é estudar um pouco da *Maldição da Dimensionalidade* (https://en.wikipedia.org/wiki/Curse_of_dimensionality). De modo mais concreto, queremos estudar a seguinte afirmação, de ordem um pouco esotética:\n",
    "\n",
    "*À medida que $p$ cresce, o volume do hipercubo $\\mathbb{H}^p = [0, 1]^p$ fica cada vez mais concentrado em sua \"casca\" do que em seu interior.*\n",
    "\n",
    "Para isso, faça o que se pede abaixo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vFEHXi_xuvXM"
   },
   "source": [
    "a) Apesar de esotérica, fazer a prova de tal afirmação é bastante simples! Seja $\\mathbb{H}^p_{\\varepsilon}$ o hipercubo contido em $\\mathbb{H}^p$ obtido removendo-se uma \"gordurinha\" de tamanho $\\varepsilon$ de sua beirada, ou seja, $\\mathbb{H}^p_{\\varepsilon} = [\\varepsilon/2, 1 - \\varepsilon/2]^p$. Mostre que o volume de $\\mathbb{H}^p_{\\varepsilon}$ converge para zero, para todo $\\varepsilon > 0$, quando $p \\to \\infty$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QWX0NgP0uvXN"
   },
   "source": [
    "b) Particularmente, para mim essa demonstação não me ajuda a ter nenhuma intuição sobre o resultado, e ele continua sendo esotérico! Porém, um dia tive uma revelação divina que cá partilho com vocês. Fixe algum valor de $0 < \\varepsilon < 1$ à sua escolha e simule $n$ vetores de tamanho $p$ de observações de uma variável aleatória uniforme no intervalo $[0, 1]$. Qual é a proporção desses vetores que não têm nenhuma observação fora do hipercubo $\\mathbb{H}^p_{\\varepsilon}$? Faça uma explicação, baseada em tal experimento, para justificar empiricamente o resultado que você provou no item a)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4rpfA1GduvXN"
   },
   "source": [
    "## Exercício 02"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DpbslqSGuvXO"
   },
   "source": [
    "O objetivo dessa questão é provar o que foi exibido sobre a maldição da dimensionalidade ao final da aula 4. Considere um conjunto de dados artificial de $n$ observações, onde cada observação consiste de um vetor de $p$ atributos, sendo cada entrada uniformemente distribuída em $(0, 1)$. Chamaremos tal conjunto de dados de $\\mathbb{X}$. Sejam $\\mathbf{X}^{(i)}$ e $\\mathbf{X}^{(j)}$ duas linhas distintas da matriz $\\mathbb{X}$, ou seja, dois vetores independentes de observações, ambos de tamanho $p$, consistindo de entradas independentes e identicamente distribuídas com distribuição uniforme no intervalo $(0, 1)$, estude o que acontece com a quantidade abaixo, chamada de *coeficiente de variação* à medida que $p \\to \\infty$:\n",
    "\n",
    "\\begin{equation*}\n",
    "\\frac{\\sqrt{\\mathbb{V}\\left(\\left\\|\\mathbf{X}^{(i)} - \\mathbf{X}^{(j)}\\right\\|^2\\right)}}{\\mathbb{E}\\left[\\left\\|\\mathbf{X}^{(i)} - \\mathbf{X}^{(j)}\\right\\|^2\\right]}.\n",
    "\\end{equation*}\n",
    "\n",
    "Relacione esse resultado com o comportamento apresentado nos *slides* da aula 4."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cY6LfQp2uvXO"
   },
   "source": [
    "# Parte prática"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uF5HdKnwuvXO"
   },
   "source": [
    "O objetivo da parte prática é analisar uma base de dados contendo informações sobre corridas de Uber, e tentar prever o valor da corrida com base em atributos de interesse. A base de dados encontra-se disponível [aqui](https://www.kaggle.com/datasets/yasserh/uber-fares-dataset).\n",
    "\n",
    "O arquivo `.csv` tem poucas colunas: `fare_amount` é a coluna que desejamos prever, e temos também as colunas abaixo para usar como preditoras:\n",
    "* `key` - _a unique identifier for each trip_\n",
    "* `pickup_datetime` - _date and time when the meter was engaged_\n",
    "* `passenger_count` - _the number of passengers in the vehicle (driver entered value)_\n",
    "* `pickup_longitude` - _the longitude where the meter was engaged_\n",
    "* `pickup_latitude` - _the latitude where the meter was engaged_\n",
    "* `dropoff_longitude` - _the longitude where the meter was disengaged_\n",
    "* `dropoff_latitude` - _the latitude where the meter was disengaged_\n",
    "\n",
    "Note que a coluna `key` não será um preditor, já que contém somente uma variável de identificação da corrida. Porém, para que as outras colunas sejam propriamente utilizadas como preditoras, talvez seja necessário algum pré-processamento:\n",
    "* Precisaremos converter as informações de latitude e longitude em distância ou nossos algoritmos serão capazes de fazê-lo \"automaticamente\"? Mesmo caso o façam, ter a distância logo de cara auxilia no processo de previsão?\n",
    "* A coluna `pickup_datetime` tem muita informação útil, e pode ser convertida em muitas outras informações para te auxiliar na predição, por exemplo: dia da semana da corrida, se é feriado ou não, etc... porém, essas informações não são imediatas e vão requerer um certo \"trabalho sujo\" da sua parte, bem como um tico de ferramentas de processamento de texto :-)\n",
    "* Note que, ao converter `pickup_datetime` para, digamos, dia da semana, será necessário converter essa informação em algo numérico. Aplicar `One Hot Encoding` é uma boa opção? Estude isso com carinho.\n",
    "\n",
    "Alguns pontos que o seu trabalho deve conter:\n",
    "* Análise exploratória bem aprofundada e interpretada: os nossos dados são muito interpretáveis! Além de fazer o que já esperamos (estudar correlações, visualizar histogramas, etc.), sua análise exploratória deve ser esclarecedora sobre distância entre ponto de partida e ponto de chegada, distribuição das corridas ao longo dos dias da semana, distribuição das corridas ao longo dos meses, estudar como (potencialmente) os atributos se relacionam com a resposta (sem e com pré-processamento), analisar (possível) influência do número de passageiros no preço da corrida, etc... Portanto, não basta fazer meia dúzia de gráficos para \"cumprir tabela\"! A análise exploratória deve informar muito sobre a base de dados e guiar os próximos passos!\n",
    "* Criação de novos atributos a partir das colunas já presentes na base\n",
    "* Treinamento e validação de todos os modelos de regressão que vimos até o momento, juntamente com uma interpretação de seus resultados\n",
    "* Em particular, os coeficientes das regressões paramétricas devem ser interpretados, bem como a `feature_importance_` dos modelos baseados em árvores.\n",
    "* Decisão de um \"melhor\" modelo para realizar previsões, com justificativa\n",
    "\n",
    "Tome cuidado que a base é grande: poucos atributos porém muitas linhas! É bem provável que você precise tomar cuidado ao usar métodos pesados como `GridSearchCV`, ou até mesmo nos métodos `.fit()` dos nossos estimadores. Usar as coisas ingenuamente pode ser computacionalmente inviável. Seja sagaz em suas escolhas!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "MachineLearning venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
